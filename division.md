üîµ Parte 1 ‚Äì Descarga y extracci√≥n de enlaces a todos los art√≠culos (Persona 1)

Objetivos:

Descargar el HTML del C√≥digo Penal desde
https://www.conceptosjuridicos.com/codigo-penal/

Identificar y extraer los enlaces a todos los art√≠culos (1 a 616 quater).

Crear una tabla/tibble con:

URL del art√≠culo

N√∫mero del art√≠culo (p. ej., ‚Äú39‚Äù o ‚Äú616 quater‚Äù)

Su jerarqu√≠a textual: Libro / T√≠tulo / Cap√≠tulo / Secci√≥n (cuando exista)

Esta persona solo entrega un dataset limpio con todos los links y jerarqu√≠as detectadas.

Salida esperada:

tabla_articulos.csv con columnas:

libro, titulo, capitulo, seccion, articulo, url

üü¢ Parte 2 ‚Äì Web scraping individual de art√≠culos y limpieza del texto (Persona 2)

Objetivos:

Usar la tabla generada en la Parte 1 para visitar cada URL.

Extraer el texto del art√≠culo, limpiarlo:

Eliminar men√∫s, notas, anuncios, etc.

Insertar \n cada ~50 caracteres (no estricto).

Generar el contexto concatenado, p. ej.:

LIBRO I: Disposiciones generales‚Ä¶
T√≠tulo III: De las penas
Cap√≠tulo I: De las penas, sus clases‚Ä¶
Secci√≥n III: De las penas privativas‚Ä¶


Preparar un tibble final con:

nombre_doc, texto_articulo, contexto, libro, titulo, capitulo, seccion, articulo


Salida esperada:

articulos_limpios.rds

üü° Parte 3 ‚Äì Construcci√≥n del corpus quanteda y docvars (Persona 3)

Objetivos:

Cargar el dataset limpio creado en la Parte 2.

Crear el corpus quanteda.

Asignar nombres de documento usando formato:

LIBRO I.T√≠tulo III.Cap√≠tulo I.Secci√≥n III.Art√≠culo 39


A√±adir las docvars requeridas:

libro

titulo

capitulo

seccion

articulo

contexto

Guardar el corpus como:

corpus_codigo_penal.rds

Salida esperada:

corpus_codigo_penal.rds listo para an√°lisis.

üü† Parte 4 ‚Äì Similaridad, distancias y dendrogramas (Persona 4)

Objetivos:

Cargar corpus_codigo_penal.rds.

Crear una matriz de documentos ‚Üí dfm ‚Üí distancias eucl√≠deas.

Construir dendrograma:

Solo texto del art√≠culo

Texto del art√≠culo + contexto concatenado

Identificar:

Los dos art√≠culos m√°s similares en cada caso.

Generar gr√°ficos y tablas con distancias m√≠nimas.

Salida esperada:

dendrograma_articulos.png

dendrograma_articulos_contexto.png

Un archivo .txt indicando qu√© art√≠culos son m√°s parecidos.

üî¥ Parte 5 ‚Äì Extracci√≥n de entidades nombradas con spacyr y udpipe (Persona 5)

Objetivos:

Cargar el corpus.

Para cada documento del corpus:

Extraer entidades nominales con spacyr
(por ejemplo usando spacy_extract_entity() o spacy_parse() + filtrado)

Extraer keywords nominales con udpipe usando RAKE

Crear tablas de frecuencia.

Mostrar:

Top 20 entidades m√°s frecuentes (spacyr)

Top 20 entidades m√°s frecuentes (udpipe)

N√∫mero de entidades comunes entre ambas listas.

Guardar resultados en:

entidades_spacyr.csv

entidades_udpipe.csv

entidades_comunes.csv

Salida esperada:

Tres archivos con las comparaciones de entidades.

‚úîÔ∏è Resultado final

Con esta divisi√≥n, cada persona tiene una tarea claramente separada:

Persona	Parte	Enfoque principal
1	Extracci√≥n de enlaces	Web scraping + jerarqu√≠as
2	Descarga y limpieza	Scraping profundo + procesamiento
3	Corpus quanteda	Corpus + docvars
4	Dendrogramas	Distancias + clustering
5	Named Entities	NLP (spacyr + udpipe)
